{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WICsVz7IUK-C"
      },
      "source": [
        "# All caesar with hint (real dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nkPpB4ddUK-G"
      },
      "outputs": [],
      "source": [
        "# import src to path\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(\"./enigma-transformed/src\")\n",
        "sys.path.append(\"./src\")\n",
        "sys.path.append(\"../src\")\n",
        "sys.path.append(\"../../src\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # try get SLURM JOB ID\n",
        "    try:\n",
        "        job_id = os.environ[\"SLURM_JOB_ID\"]\n",
        "    except:\n",
        "        job_id = \"debug\"\n",
        "    logdir = f\"logs/slurm_{job_id}\"\n",
        "    os.makedirs(logdir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fPcc-zjUK-I"
      },
      "source": [
        "## Setup and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wx0VpThdUK-I"
      },
      "outputs": [],
      "source": [
        "dataset_size = 8000\n",
        "dataset_min_len = 50\n",
        "dataset_max_len = 50\n",
        "seed = 39  # reproducible\n",
        "evaluate_on_test = True \n",
        "device = 'cuda:0'\n",
        "train_epochs = 30\n",
        "lr = 2e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxkzLdIUK-J"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0. (optional) get data and preprocess it\n",
        "import os\n",
        "import utils\n",
        "from preprocessing import preprocess_file\n",
        "\n",
        "data_path = 'news.2012.en.shuffled.deduped'\n",
        "if not os.path.exists(data_path):\n",
        "    utils.download_newscrawl(2012,'en')\n",
        "    preprocess_file(data_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ByT5Dataset\n",
        "import torch.utils.data\n",
        "from preprocessing import load_dataset, prepend_hello\n",
        "\n",
        "dataset = load_dataset(dataset_size, dataset_min_len, dataset_max_len, data_path, seed)\n",
        "\n",
        "generator1 = torch.Generator().manual_seed(seed)\n",
        "train_ex, dev_ex, test_ex = torch.utils.data.random_split(\n",
        "    dataset,\n",
        "    [round(0.8 * dataset_size), round(0.1 * dataset_size), round(0.1 * dataset_size)],\n",
        "    generator=generator1,\n",
        ")\n",
        "# Prepend 'hello' to each example so the model has something constant in each example from which to infer the shift\n",
        "train = ByT5Dataset.ByT5CaesarRandomWithHelloHintDataset(train_ex, max_length=dataset_max_len)\n",
        "dev = ByT5Dataset.ByT5CaesarRandomWithHelloHintDataset(dev_ex, max_length=dataset_max_len)\n",
        "test = ByT5Dataset.ByT5CaesarRandomWithHelloHintDataset(test_ex, max_length=dataset_max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdOImRcwUK-K"
      },
      "source": [
        "## Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9cPfwbFXUK-K"
      },
      "outputs": [],
      "source": [
        "# We want a T5 architecutre but severely reduced in size\n",
        "from transformers import ByT5Tokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = ByT5Tokenizer()\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oOeq34mUK-K"
      },
      "source": [
        "## Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zMfxxuj8UK-L"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from transformers import (\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=logdir + \"/output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=train_epochs,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    # accumulate gradients to simulate higher batch size\n",
        "    gradient_accumulation_steps=8,\n",
        "    save_total_limit=0,\n",
        "    predict_with_generate=True,\n",
        "    push_to_hub=False,\n",
        "    logging_dir=logdir,\n",
        "    learning_rate=lr,\n",
        "    warmup_ratio=0.2,\n",
        "    save_steps=10000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktmjB6o1UK-L"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "KcNWBgIbUK-L",
        "outputId": "849f1078-3326-403c-d156-4e8f56060aa1"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=dev,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(logdir + \"/model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEXtnYacUK-M"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jUmG6DrqUK-M"
      },
      "outputs": [],
      "source": [
        "if evaluate_on_test:\n",
        "    pass\n",
        "else:\n",
        "    test = dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT3jPUPfUK-M",
        "outputId": "a48b121b-c40a-4014-f3b9-ccd8e1069920"
      },
      "outputs": [],
      "source": [
        "from utils import levensthein_distance, print_avg_median_mode_error\n",
        "from transformers import pipeline, logging\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "\n",
        "error_counts = []\n",
        "translate = pipeline(\"translation\", model=model, tokenizer=tokenizer, device=device)\n",
        "for index in range(len(test)):\n",
        "    generated = translate(test[index][\"input_text\"], max_length=(dataset_max_len+1)*2)[0][\"translation_text\"]\n",
        "    error_counts.append(levensthein_distance(generated, test[index][\"output_text\"]))\n",
        "    if error_counts[-1] > 0:\n",
        "        print(f\"Example {index}, error count {error_counts[-1]}\")\n",
        "        print(\"In :\", test[index][\"input_text\"])\n",
        "        print(\"Gen:\", generated)\n",
        "        expected = test[index][\"output_text\"]\n",
        "        print(\"Exp:\", expected)\n",
        "    else:\n",
        "        print(f\"Example {index} OK\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "print_avg_median_mode_error(error_counts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
