{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0ed4e9",
   "metadata": {},
   "source": [
    "\n",
    "# Vignere cipher (all possible settings, length 3) on news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0754331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# half precision and optimized\n",
    "# import src to path\n",
    "import sys\n",
    "import os\n",
    "import src.ciphers as ciphers\n",
    "import src.ByT5Dataset as ByT5Dataset\n",
    "import src.utils as utils\n",
    "import src.evaluation as evaluation\n",
    "import src.preprocessing as preprocessing\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # try get SLURM JOB ID\n",
    "    try:\n",
    "        job_id = os.environ[\"SLURM_JOB_ID\"]\n",
    "    except:\n",
    "        job_id = \"debug\"\n",
    "    logdir = f\"logs/slurm_{job_id}\"\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "\n",
    "# ## Setup and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d65cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import calculate_batch_size\n",
    "\n",
    "dataset_size = 100000\n",
    "dataset_min_len = 200\n",
    "dataset_max_len = 200\n",
    "seed = 39  # reproducible\n",
    "evaluate_on_test = True\n",
    "device = \"cuda:0\"\n",
    "train_epochs = 40\n",
    "lr = 2e-3\n",
    "warmup_ratio = 0.2\n",
    "\n",
    "tartget_batch_size = 192\n",
    "batch_size, grad_acc_steps = calculate_batch_size(tartget_batch_size, dataset_max_len)\n",
    "# batch_size, grad_acc_steps = 16, 12\n",
    "print(f\"batch_size: {batch_size}, grad_acc_steps: {grad_acc_steps}\")\n",
    "# 100k dataset 40 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0aea5f",
   "metadata": {},
   "source": [
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. (optional) get data and preprocess it\n",
    "import os\n",
    "import src.utils\n",
    "from src.preprocessing import preprocess_file\n",
    "\n",
    "data_path = \"news.2012.de.shuffled.deduped\"\n",
    "if not os.path.exists(data_path):\n",
    "    utils.download_newscrawl(2012, \"de\")\n",
    "    preprocess_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.ByT5Dataset\n",
    "import torch.utils.data\n",
    "from src.preprocessing import load_dataset, preprocess_text\n",
    "\n",
    "dataset = load_dataset(dataset_size, dataset_min_len, dataset_max_len, data_path, seed)\n",
    "dataset = [preprocess_text(text) for text in dataset]\n",
    "generator1 = torch.Generator().manual_seed(seed)\n",
    "train_ex, dev_ex, test_ex = torch.utils.data.random_split(\n",
    "    dataset,  # type: ignore\n",
    "    [round(0.8 * dataset_size), round(0.1 * dataset_size), round(0.1 * dataset_size)],\n",
    "    generator=generator1,\n",
    ")\n",
    "dataset_class = ByT5Dataset.ByT5NoisyVignere3Dataset\n",
    "\n",
    "train = dataset_class(train_ex, max_length=dataset_max_len)\n",
    "dev = dataset_class(dev_ex, max_length=dataset_max_len)\n",
    "test = dataset_class(test_ex, max_length=dataset_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb3603",
   "metadata": {},
   "source": [
    "\n",
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want a T5 architecutre but severely reduced in size\n",
    "from transformers import ByT5Tokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "tokenizer = ByT5Tokenizer()\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-small\", \n",
    "# torch_dtype=torch.bfloat16\n",
    ")\n",
    "# model = model.half() \n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a87e6",
   "metadata": {},
   "source": [
    "\n",
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3538f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=logdir + \"/output\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    # accumulate gradients to simulate higher batch size\n",
    "    gradient_accumulation_steps=grad_acc_steps,\n",
    "    # save_total_limit=0,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    "    logging_dir=logdir,\n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    save_steps=500,\n",
    "    # fp16=True,\n",
    ")\n",
    "\n",
    "\n",
    "# ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "wandb.init(project=\"vignere3_noisy_news_de\")\n",
    "print('training time')\n",
    "trainer.train()\n",
    "trainer.save_model(logdir + \"/model\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "enigmavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
