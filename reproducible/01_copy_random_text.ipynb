{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic demo: teaching to copy (random characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src to path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # try get SLURM JOB ID\n",
    "    try:\n",
    "        job_id = os.environ['SLURM_JOB_ID']\n",
    "    except:\n",
    "        job_id = 'debug'\n",
    "    logdir = f'logs/{job_id}'\n",
    "    os.makedirs(logdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ciphers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import torch.utils.data\n",
    "dataset = preprocessing.generate_dataset(rows=2000, min_length=50, max_length=50)\n",
    "# using torch .8, .1 .1\n",
    "\n",
    "# apply cipher to get pairs\n",
    "training_pairs = [(ciphers.nothing(t), t) for t in dataset]\n",
    "\n",
    "train, dev, test = torch.utils.data.random_split(dataset, [1600, 200, 200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual training\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "tokenizer = transformers.ByT5Tokenizer()\n",
    "\n",
    "# colla\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
