{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate performance along various axes of sentence complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"./enigma-transformed/src\")\n",
    "sys.path.append(\"./src\")\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_column: unigram_js_divergence\n"
     ]
    }
   ],
   "source": [
    "available_eval_columns = [ # actually AAAAA these are all with the english model... after | there will be with the actual model \n",
    "    \"unigram_js_divergence\",  # 17602 old, 18204; german: 18248 ; czech: 18251 | de: 18303 ; cs: 18351 (almost); 18533\n",
    "    \"gpt2_tokens_per_char\",  #  17659 old, 18206; german: 18249; czech: 18252 | de: 18304 ; cs: 18354 almost; 18532\n",
    "    \"gpt2_perplexity\",  # 17604 old, 18207; german: ...; czech: | de: 19096 ; cs: 18361 (almost... but not quite); 18531\n",
    "    \"bigram_js_divergence\",  # 17657, 18209; german: 18250 ; czech: 18258 | de: 18305 ; cs: 18486\n",
    "    \"depth_of_parse_tree\", #17687, 221; german: 18293 ; czech:| de: 18306 ; cs: 18485\n",
    "    \"named_entities\", #17688, 222; german: 18290 ; czech: | de: 18307 ; cs: 18484\n",
    "    \"pos_js_divergence\", #17689 23; german: 18291 ; czech: | de: 18322 ; cs: 18483\n",
    "    \"pos_bigram_js_divergence\" #17690  24; german: 18292 ; czech: | de: 18325 ; cs: 18482\n",
    "]\n",
    "eval_column = available_eval_columns[2]\n",
    "lang='de'\n",
    "print(\"eval_column:\", eval_column)\n",
    "dataset_max_len = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 898502\n",
      "len: 850701\n",
      "len: 847588\n",
      "data loaded\n",
      "data sorted\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = f\"news.2013.{lang}.trainlen.{dataset_max_len}.merged.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "# print len\n",
    "print(\"len:\", len(data))\n",
    "\n",
    "# filter out rows which 'lang' != True\n",
    "data = data[data['lang'] == True]\n",
    "print(\"len:\", len(data))\n",
    "# weird is false\n",
    "data = data[data['weird'] == False]\n",
    "\n",
    "# print len\n",
    "print(\"len:\", len(data))\n",
    "print(\"data loaded\")\n",
    "# sort by eval column\n",
    "data.sort_values(eval_column, inplace=True)\n",
    "print(\"data sorted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 rows\n",
    "print(f\"{data.head(10)=}\")\n",
    "# last 10 rows\n",
    "print(f\"{data.tail(10)=}\")\n",
    "\n",
    "rows = {\n",
    "    0.1: data.iloc[len(data) // 1000 * 999 - 1000 : len(data) // 1000 * 999],\n",
    "    1: data.iloc[len(data) // 100 * 99 - 1000 : len(data) // 100 * 99],\n",
    "    5: data.iloc[len(data) // 100 * 95 - 1000 : len(data) // 100 * 95],\n",
    "    10: data.iloc[len(data) // 100 * 90 - 1000 : len(data) // 100 * 90],\n",
    "    15: data.iloc[len(data) // 100 * 85 - 1000 : len(data) // 100 * 85],\n",
    "    20: data.iloc[len(data) // 100 * 80 - 1000 : len(data) // 100 * 80],\n",
    "    25: data.iloc[len(data) // 100 * 75 - 1000 : len(data) // 100 * 75],\n",
    "    30: data.iloc[len(data) // 100 * 70 - 1000 : len(data) // 100 * 70],\n",
    "    35: data.iloc[len(data) // 100 * 65 - 1000 : len(data) // 100 * 65],\n",
    "    40: data.iloc[len(data) // 100 * 60 - 1000 : len(data) // 100 * 60],\n",
    "    45: data.iloc[len(data) // 100 * 55 - 1000 : len(data) // 100 * 55],\n",
    "    50: data.iloc[len(data) // 100 * 50 - 1000 : len(data) // 100 * 50],\n",
    "    55: data.iloc[len(data) // 100 * 45 - 1000 : len(data) // 100 * 45],\n",
    "    60: data.iloc[len(data) // 100 * 40 - 1000 : len(data) // 100 * 40],\n",
    "    65: data.iloc[len(data) // 100 * 35 - 1000 : len(data) // 100 * 35],\n",
    "    70: data.iloc[len(data) // 100 * 30 - 1000 : len(data) // 100 * 30],\n",
    "    75: data.iloc[len(data) // 100 * 25 - 1000 : len(data) // 100 * 25],\n",
    "    80: data.iloc[len(data) // 100 * 20 - 1000 : len(data) // 100 * 20],\n",
    "    85: data.iloc[len(data) // 100 * 15 - 1000 : len(data) // 100 * 15],\n",
    "    90: data.iloc[len(data) // 100 * 10 - 1000 : len(data) // 100 * 10],\n",
    "    95: data.iloc[len(data) // 100 * 5 - 1000 : len(data) // 100 * 5],\n",
    "    99: data.iloc[len(data) // 100 * 1 - 1000 : len(data) // 100 * 1],\n",
    "    99.9: data.iloc[len(data) // 1000 * 1 - 1000 : len(data) // 1000 * 1],\n",
    "}\n",
    "if len(rows[99.9]) == 0: # bug for datasets with < 1M rows\n",
    "    rows[99.9] = data.iloc[:1000]\n",
    "else:\n",
    "    print('if czech something weird happened, otherwise ok')\n",
    "print(\"percentile rows split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ByT5Tokenizer, T5ForConditionalGeneration\n",
    "from src.utils import levensthein_distance, print_avg_median_mode_error\n",
    "from transformers import pipeline, logging\n",
    "import torch\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "\n",
    "tokenizer = ByT5Tokenizer()\n",
    "\n",
    "from src.ByT5Dataset import ByT5CaesarRandomDataset, ByT5ConstEnigmaDataset\n",
    "# aaaaaa\n",
    "model_ids = {\n",
    "    'caesar': 'slurm_16677',\n",
    "    'en': 'slurm_17510',\n",
    "    'de': 'slurm_18065',\n",
    "    'cs': 'slurm_18066'\n",
    "}\n",
    "model_id = model_ids[lang]\n",
    "model = T5ForConditionalGeneration.from_pretrained(f\"./logs/{model_id}/model\")\n",
    "dataset_class = ByT5ConstEnigmaDataset  # for 17510 model\n",
    "# dataset_class = ByT5CaesarRandomDataset # for 16677 model\n",
    "rows_datasets = {i: dataset_class(list(rows[i].text), dataset_max_len) for i in rows}\n",
    "\n",
    "print(\"rows_datasets created\")\n",
    "\n",
    "averages, medians, modes = {}, {}, {}\n",
    "raw_data = {}\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "for i, test in rows_datasets.items():\n",
    "    print(f\"#############################################\")\n",
    "    print(f\"Testing {i}th percentile\")\n",
    "    error_counts = []\n",
    "    translate = pipeline(\"translation\", model=model, tokenizer=tokenizer, device=device)\n",
    "    for index in range(len(test)):\n",
    "        generated = translate(\n",
    "            test[index][\"input_text\"], max_length=(dataset_max_len + 1) * 2\n",
    "        )[0][\"translation_text\"]\n",
    "        error_counts.append(levensthein_distance(generated, test[index][\"output_text\"]))\n",
    "        if error_counts[-1] > 0:\n",
    "            print(f\"Example {index}, error count {error_counts[-1]}\")\n",
    "            print(\"In :\", test[index][\"input_text\"])\n",
    "            print(\"Gen:\", generated)\n",
    "            expected = test[index][\"output_text\"]\n",
    "            print(\"Exp:\", expected)\n",
    "        else:\n",
    "            print(f\"Example {index} OK\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "    avg, med, mode = print_avg_median_mode_error(error_counts)\n",
    "    averages[i] = avg\n",
    "    medians[i] = med\n",
    "    modes[i] = mode\n",
    "    raw_data[i] = error_counts\n",
    "\n",
    "print(\"Averages:\", averages)\n",
    "print(\"Medians:\", medians)\n",
    "print(\"Modes:\", modes)\n",
    "print(\"Raw data:\", raw_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigmavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
