{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate performance along various axes of sentence complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. load dataset to csv\n",
    "2. load the model \n",
    "3. run the model function on each sentence in dataset...\n",
    "4. batch this process... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang='de' #cs: 19359 #en: 19360  #de: 19387\n",
    "dataset_max_len = 200\n",
    "len_of_dataset = 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 898502\n",
      "len: 850701\n",
      "len: 847588\n",
      "data loaded\n",
      "len: 256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = f\"news.2013.{lang}.trainlen.{dataset_max_len}.merged.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "# print len\n",
    "print(\"len:\", len(data))\n",
    "\n",
    "# filter out rows which 'lang' != True\n",
    "data = data[data['lang'] == True]\n",
    "print(\"len:\", len(data))\n",
    "# weird is false\n",
    "data = data[data['weird'] == False]\n",
    "\n",
    "# print len\n",
    "print(\"len:\", len(data))\n",
    "print(\"data loaded\")\n",
    "\n",
    "# sample data\n",
    "data = data.sample(n=len_of_dataset, random_state=1)\n",
    "print(\"len:\", len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/16 in 77.57 seconds\n",
      "Processed batch 2/16 in 153.34 seconds\n",
      "Processed batch 3/16 in 218.47 seconds\n",
      "Processed batch 4/16 in 285.92 seconds\n",
      "Processed batch 5/16 in 353.50 seconds\n",
      "Processed batch 6/16 in 430.63 seconds\n",
      "Processed batch 7/16 in 491.84 seconds\n",
      "Processed batch 8/16 in 551.48 seconds\n",
      "Processed batch 9/16 in 614.72 seconds\n",
      "Processed batch 10/16 in 674.50 seconds\n",
      "Processed batch 11/16 in 731.88 seconds\n",
      "Processed batch 12/16 in 797.07 seconds\n",
      "Processed batch 13/16 in 871.31 seconds\n",
      "Processed batch 14/16 in 941.20 seconds\n",
      "Processed batch 15/16 in 1013.33 seconds\n",
      "Processed batch 16/16 in 1087.18 seconds\n",
      "Average errors: 88.78125\n",
      "Median errors: 87\n",
      "Mode errors: 71\n",
      "#############################################\n",
      "avg: 88.78125\n",
      "med: 87\n",
      "mode: 71\n"
     ]
    }
   ],
   "source": [
    "from transformers import ByT5Tokenizer, T5ForConditionalGeneration\n",
    "from src.utils import levensthein_distance, print_avg_median_mode_error\n",
    "from transformers import pipeline, logging\n",
    "from src.ByT5Dataset import ByT5CaesarRandomDataset, ByT5ConstEnigmaDataset\n",
    "import torch\n",
    "import time\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "\n",
    "tokenizer = ByT5Tokenizer()\n",
    "\n",
    "# aaaaaa\n",
    "model_ids = {\n",
    "    'caesar': 'slurm_16677',\n",
    "    'en': 'slurm_17510',\n",
    "    'de': 'slurm_18065',\n",
    "    'cs': 'slurm_18066'\n",
    "}\n",
    "model_id = model_ids[lang]\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(f\"./logs/{model_id}/model\")\n",
    "model.to(device)\n",
    "dataset_class = ByT5ConstEnigmaDataset  # for 17510 model\n",
    "# dataset_class = ByT5CaesarRandomDataset # for 16677 model\n",
    "dataset = dataset_class(data.text, dataset_max_len)\n",
    "data['generated_text'] = ''\n",
    "data['error_count'] = 0\n",
    "\n",
    "\n",
    "\n",
    "translate = pipeline(\"translation\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "batch_size = 64\n",
    "data = data.reset_index(drop=True)\n",
    "for i in range(0, len(dataset), batch_size):\n",
    "    t0 = time.time()\n",
    "    batch = dataset[i:i+batch_size]\n",
    "    input_texts = batch['input_text'] \n",
    "    output_texts = batch['output_text'] \n",
    "\n",
    "    # Generate translations in batches\n",
    "    generated_texts = translate(input_texts, max_length=(dataset_max_len + 1) * 2)\n",
    "    generated_texts = [t['translation_text'] for t in generated_texts]\n",
    "\n",
    "    # Calculate errors and update DataFrame\n",
    "    errors = [levensthein_distance(gen, out) for gen, out in zip(generated_texts, output_texts)]\n",
    "    data.loc[i:i+batch_size-1, 'generated_text'] = generated_texts\n",
    "    data.loc[i:i+batch_size-1, 'error_count'] = errors\n",
    "    t1 = time.time()\n",
    "\n",
    "    print(f\"Processed batch {i // batch_size + 1}/{len(dataset) // batch_size} in {t1 - t0:.2f} seconds\")\n",
    "\n",
    "\n",
    "avg, med, mode = print_avg_median_mode_error(data['error_count'].tolist())\n",
    "print(\"#############################################\")\n",
    "\n",
    "print(\"avg:\", avg)\n",
    "print(\"med:\", med)\n",
    "print(\"mode:\", mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.to_csv(f\"news.2013.{lang}.trainlen.{dataset_max_len}.evaluation.{len_of_dataset}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigmavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
