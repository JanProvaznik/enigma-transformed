{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from collections import Counter\n",
    "import torch\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from src.evaluation import js_divergence\n",
    "# what functions are avaliable to measure?\n",
    "\n",
    "# 1. unigram js_divergence\n",
    "# 2. bpe\n",
    "# 3. bigram js_divergence\n",
    "# 4. gpt2 perplexity\n",
    "# 5. depth of parse tree\n",
    "# 6. js_divergence of POS tags\n",
    "# 7. js_divergence of POS bigrams\n",
    "# 8. number of named entities \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_gpt2_perplexity():\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    device = (\n",
    "        torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    )\n",
    "    gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "    def gpt2_perplexity(text):\n",
    "        # Encode and prepare inputs\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Calculate log likelihood\n",
    "        with torch.no_grad():\n",
    "            outputs = gpt2(**inputs, labels=inputs[\"input_ids\"])\n",
    "        log_likelihood = outputs.loss.item()\n",
    "\n",
    "        # Calculate perplexity\n",
    "        perplexity = torch.exp(torch.tensor(log_likelihood)).item()\n",
    "\n",
    "        return perplexity\n",
    "    return gpt2_perplexity\n",
    "\n",
    "\n",
    "def create_bpe_tokens_per_char():\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    def bpe_tokens_per_char(text):\n",
    "        chars = len(text)\n",
    "        tokens = len(tokenizer.encode(text))\n",
    "        return tokens / chars\n",
    "    return bpe_tokens_per_char\n",
    "\n",
    "\n",
    "def find_depth(node):\n",
    "    if not list(node.children):\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + max(find_depth(child) for child in node.children)\n",
    "\n",
    "\n",
    "def create_all_nlp_functions_de(data):\n",
    "    nlp = spacy.load(\"de_core_news_md\")\n",
    "    counts_bigram_pos = Counter()\n",
    "    counts_pos = Counter()\n",
    "    for text in data.original_text:\n",
    "        doc = nlp(text)\n",
    "        pos = [token.pos_ for token in doc]\n",
    "        counts_pos.update(pos)\n",
    "        counts_bigram_pos.update(zip(pos, pos[1:]))\n",
    "\n",
    "    def inner(text):\n",
    "        doc = nlp(text)\n",
    "        pos = [token.pos_ for token in doc]\n",
    "        pos_js_divergence = js_divergence(counts_pos, Counter(pos))\n",
    "        pos_bigram_js_divergence = js_divergence(counts_bigram_pos, Counter(zip(pos, pos[1:])))\n",
    "        root = [token for token in doc if token.head == token][0]\n",
    "        depth = find_depth(root)\n",
    "        named_entities = len(doc.ents)\n",
    "\n",
    "        \n",
    "        return pos_js_divergence, pos_bigram_js_divergence, depth, named_entities\n",
    "    return inner\n",
    "\n",
    "\n",
    "def create_char_bigram_divergences(data):\n",
    "    unigram_counts = Counter()\n",
    "    bigram_counts = Counter()\n",
    "    for text in data.text:\n",
    "        unigram_counts.update(text)\n",
    "        bigram_counts.update(zip(text, text[1:]))\n",
    "    def inner(text):\n",
    "        unigram_divergence = js_divergence(unigram_counts, Counter(text))\n",
    "        bigram_divergence = js_divergence(bigram_counts, Counter(zip(text, text[1:])))\n",
    "        return unigram_divergence, bigram_divergence\n",
    "    return inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        original_text  \\\n",
      "0   Frankfurt/Main (dpa) - An der Frankfurter Wert...   \n",
      "1   Lieber steigt sie morgens um 7.50 Uhr in den Z...   \n",
      "2   Und sowohl Schelberg als auch Fischer betonten...   \n",
      "3   Islamabad - Nach dem tödlichen US-Drohnenangri...   \n",
      "4   So bietet die Kanalinsel Guernsey seit Anfang ...   \n",
      "5   Vor dem Schlusssegen dankte Pfarrer Bernold Ra...   \n",
      "6   Mittwochabend hat die Film-Crew am Kühlen Brun...   \n",
      "7   Der britische Sprintstar setzte sich auf dem f...   \n",
      "8   Mit seinen Aktionen sensibilisiert der \"Tag de...   \n",
      "9   Im Vielseitigkeitswettkampf IV waren gleich zw...   \n",
      "10  Einen Kommentar von Andreas Helfer zum Etappen...   \n",
      "11  Düsseldorf - Leverkusens Mittelfeldspieler Hil...   \n",
      "12  Am liebsten wäre sie wohl abgetaucht im Schwim...   \n",
      "13  \"Ich wünsche Ihnen viel Glück und eine gute Ha...   \n",
      "14  Mit der Mission zur Überforderung lässt es die...   \n",
      "15  Nach dem im September 2011 beschlossenen Konze...   \n",
      "16  Ein dramatischer Zwischenfall ereignete sich a...   \n",
      "17  \"Durch die Schaffung von verschiedenen Ebenen ...   \n",
      "18  Die mit Wiederaufbau, Wirtschaftsaufschwung un...   \n",
      "19  Der Regierungschef, so scheint es, setzt anges...   \n",
      "20  Sie wollen ihre Kirchturmuhr nicht abschalten ...   \n",
      "21  In der Folge müssten entweder ganze Straßenzüg...   \n",
      "22  Der Heidelberger Juraprofessor und sein deutsc...   \n",
      "23  Ein 48-jähriger Obdachloser ist in der Nacht a...   \n",
      "24  Unter freiem Himmel auf der Veranstaltungsbühn...   \n",
      "25  Dies erfolgte laut Fliegerstaffel auch im Vorf...   \n",
      "26  Angesichts der außergewöhnlichen Abgeordnetend...   \n",
      "27  Alles in allem waren sich die Ausschussmitglie...   \n",
      "28  Mehr als 300 Klienten würden von den drei Sozi...   \n",
      "29  Darum wende ich mich nun an Sie mit der Frage,...   \n",
      "30  Der Engländer hatte vergeblich versucht, mit S...   \n",
      "31  Dies sollte über die Abschaffung des Solis ges...   \n",
      "32  Auf der Bundesstraße 3 kurz vor Bovenden fuhr ...   \n",
      "33  Der Besitzer sowie der Geschäftsführer der grö...   \n",
      "34  Bislang sind auf der eGk nur die Stammdaten de...   \n",
      "35  Obwohl die Reinigung der über 700 Pfeifen den ...   \n",
      "36  Der 35- Jährige und die mutmaßlichen Täter kan...   \n",
      "37  Zu einem aktuell diskutierten Thema: Vor einem...   \n",
      "38  Der Investor Rudolf Haberleitner aus Österreic...   \n",
      "39  Zwischen Dr. Michael Eldred (links), Moderator...   \n",
      "40  Um 17 Uhr hat der Wiesbadener Bläserkreis unte...   \n",
      "41  Jonas Bauhaus, der im Wohnzimmer eines Reihenh...   \n",
      "42  Die Einwechslung von Stürmerstar Diego Forlan,...   \n",
      "43  Ein Erfolg - denn mit großem Engagement erschu...   \n",
      "44  Laut Anklage hat er seine Frau zuerst gewürgt,...   \n",
      "45  Bei dessen Umsetzung wird aber teilweise offen...   \n",
      "46  Suchmaschinen müssen demnach Wortkombinationen...   \n",
      "47  Der Vorstellung des Anbaugebietes folgten dabe...   \n",
      "48  Quelle: OÖNachrichten Zeitung Artikel: http://...   \n",
      "\n",
      "                                                 text  pos_js_divergence  \\\n",
      "0   frankfurtmain dpa an der frankfurter wertpapie...           0.291640   \n",
      "1   lieber steigt sie morgens um uhr in den zug na...           0.223809   \n",
      "2   und sowohl schelberg als auch fischer betonten...           0.298448   \n",
      "3   islamabad nach dem todlichen usdrohnenangriff ...           0.297539   \n",
      "4   so bietet die kanalinsel guernsey seit anfang ...           0.158986   \n",
      "5   vor dem schlusssegen dankte pfarrer bernold ra...           0.282245   \n",
      "6   mittwochabend hat die filmcrew am kuhlen brunn...           0.228876   \n",
      "7   der britische sprintstar setzte sich auf dem f...           0.285967   \n",
      "8   mit seinen aktionen sensibilisiert der tag der...           0.268625   \n",
      "9   im vielseitigkeitswettkampf iv waren gleich zw...           0.262733   \n",
      "10  einen kommentar von andreas helfer zum etappen...           0.254377   \n",
      "11  dusseldorf leverkusens mittelfeldspieler hilbe...           0.274546   \n",
      "12  am liebsten ware sie wohl abgetaucht im schwim...           0.199013   \n",
      "13  ich wunsche ihnen viel gluck und eine gute han...           0.165508   \n",
      "14  mit der mission zur uberforderung lasst es die...           0.198370   \n",
      "15  nach dem im september beschlossenen konzept zu...           0.282915   \n",
      "16  ein dramatischer zwischenfall ereignete sich a...           0.181604   \n",
      "17  durch die schaffung von verschiedenen ebenen u...           0.208575   \n",
      "18  die mit wiederaufbau wirtschaftsaufschwung und...           0.260541   \n",
      "19  der regierungschef so scheint es setzt angesic...           0.231357   \n",
      "20  sie wollen ihre kirchturmuhr nicht abschalten ...           0.299648   \n",
      "21  in der folge mussten entweder ganze strassenzu...           0.312701   \n",
      "22  der heidelberger juraprofessor und sein deutsc...           0.352456   \n",
      "23  ein jahriger obdachloser ist in der nacht auf ...           0.265835   \n",
      "24  unter freiem himmel auf der veranstaltungsbuhn...           0.271215   \n",
      "25  dies erfolgte laut fliegerstaffel auch im vorf...           0.229837   \n",
      "26  angesichts der aussergewohnlichen abgeordneten...           0.227087   \n",
      "27  alles in allem waren sich die ausschussmitglie...           0.294702   \n",
      "28  mehr als klienten wurden von den drei sozialst...           0.277785   \n",
      "29  darum wende ich mich nun an sie mit der frage ...           0.329637   \n",
      "30  der englander hatte vergeblich versucht mit sc...           0.236267   \n",
      "31  dies sollte uber die abschaffung des solis ges...           0.244802   \n",
      "32  auf der bundesstrasse kurz vor bovenden fuhr g...           0.293248   \n",
      "33  der besitzer sowie der geschaftsfuhrer der gro...           0.282817   \n",
      "34  bislang sind auf der egk nur die stammdaten de...           0.293516   \n",
      "35  obwohl die reinigung der uber pfeifen den gros...           0.198702   \n",
      "36  der jahrige und die mutmasslichen tater kannte...           0.231255   \n",
      "37  zu einem aktuell diskutierten thema vor einem ...           0.298842   \n",
      "38  der investor rudolf haberleitner aus osterreic...           0.244137   \n",
      "39  zwischen dr michael eldred links moderator dr ...           0.257848   \n",
      "40  um uhr hat der wiesbadener blaserkreis unter d...           0.267066   \n",
      "41  jonas bauhaus der im wohnzimmer eines reihenha...           0.246218   \n",
      "42  die einwechslung von sturmerstar diego forlan ...           0.212247   \n",
      "43  ein erfolg denn mit grossem engagement erschuf...           0.236571   \n",
      "44  laut anklage hat er seine frau zuerst gewurgt ...           0.196036   \n",
      "45  bei dessen umsetzung wird aber teilweise offen...           0.260967   \n",
      "46  suchmaschinen mussen demnach wortkombinationen...           0.289462   \n",
      "47  der vorstellung des anbaugebietes folgten dabe...           0.215112   \n",
      "48  quelle oonachrichten zeitung artikel httpwwwna...           0.564721   \n",
      "\n",
      "    pos_bigram_js_divergence  depth_of_parse_tree  named_entities  \n",
      "0                   0.535610                    4               6  \n",
      "1                   0.493948                    7               2  \n",
      "2                   0.592172                    7               4  \n",
      "3                   0.543405                    9               6  \n",
      "4                   0.500783                    9               3  \n",
      "5                   0.547538                    7               1  \n",
      "6                   0.518300                    8               0  \n",
      "7                   0.533131                   13               6  \n",
      "8                   0.523196                    6               2  \n",
      "9                   0.558642                    6               3  \n",
      "10                  0.491544                    7               2  \n",
      "11                  0.591862                    7               3  \n",
      "12                  0.496469                    8               2  \n",
      "13                  0.482919                   10               2  \n",
      "14                  0.504503                    7               2  \n",
      "15                  0.565939                    9               2  \n",
      "16                  0.524399                    5               1  \n",
      "17                  0.518818                    8               1  \n",
      "18                  0.550610                   11               0  \n",
      "19                  0.523311                   10               0  \n",
      "20                  0.582032                    9               1  \n",
      "21                  0.582286                   10               0  \n",
      "22                  0.587118                   10               6  \n",
      "23                  0.521189                   12               2  \n",
      "24                  0.511887                    9               4  \n",
      "25                  0.534830                    7               3  \n",
      "26                  0.521058                    9               2  \n",
      "27                  0.587013                   10               1  \n",
      "28                  0.563197                    7               2  \n",
      "29                  0.556955                   12               1  \n",
      "30                  0.565676                    9               3  \n",
      "31                  0.548657                    7               2  \n",
      "32                  0.562854                    5               3  \n",
      "33                  0.519977                   10               1  \n",
      "34                  0.560118                    6               2  \n",
      "35                  0.535644                    8               0  \n",
      "36                  0.552370                    5               0  \n",
      "37                  0.554620                    4               2  \n",
      "38                  0.550700                    7               4  \n",
      "39                  0.575089                    6               1  \n",
      "40                  0.513072                    7               4  \n",
      "41                  0.460831                    8               3  \n",
      "42                  0.546884                   11               3  \n",
      "43                  0.479912                    7               0  \n",
      "44                  0.543444                    9               1  \n",
      "45                  0.520889                    8               0  \n",
      "46                  0.592242                    5               0  \n",
      "47                  0.497682                    6               0  \n",
      "48                  0.774132                    4               2  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/provaja/enigma-transformed/measure_dataset_de.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baic/home/provaja/enigma-transformed/measure_dataset_de.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m exit(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baic/home/provaja/enigma-transformed/measure_dataset_de.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m processing_now\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baic/home/provaja/enigma-transformed/measure_dataset_de.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m fn_name, function, src_col \u001b[39m=\u001b[39m available_functions[processing_now]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baic/home/provaja/enigma-transformed/measure_dataset_de.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mfn_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baic/home/provaja/enigma-transformed/measure_dataset_de.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# function = bpe_tokens_per_char\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"news.2013.de.trainlen.200.csv\")\n",
    "# data = pd.read_csv(\"news.test.de.csv\")\n",
    "available_functions = [\n",
    "    # (\"gpt2_perplexity\", create_gpt2_perplexity(), 'text'), # done\n",
    "    # (\"bpe_tokens_per_char\", create_bpe_tokens_per_char(), 'text'), # done\n",
    "    # (\"unigram_js_divergence\", create_unigram_js_divergence(data), 'text'), #done\n",
    "    # (\"bigram_js_divergence\", create_bigram_js_divergence(data), 'text'),#17648\n",
    "    # (\"pos_js_divergence\", create_pos_js_divergence(data),'original_text'), #17650\n",
    "    # (\"pos_bigram_js_divergence\", create_pos_bigram_js_divergence(data), 'original_text'), #17655\n",
    "    # (\"depth_of_parse_tree\", create_depth_of_parse_tree(), 'original_text'),#17652\n",
    "    # (\"named_entities\", create_named_entities(),'original_text')#17649\n",
    "]\n",
    "\n",
    "# compute all nlp things at once!\n",
    "# nlpfuncs= create_all_nlp_functions_de(data)\n",
    "# data[\"pos_js_divergence\"], data[\"pos_bigram_js_divergence\"], data[\"depth_of_parse_tree\"], data[\"named_entities\"] = zip(*data.original_text.apply(lambda text: nlpfuncs(text)))\n",
    "\n",
    "\n",
    "# compute char divergences\n",
    "# char_divergences = create_char_bigram_divergences(data)\n",
    "# print(\"fn created\")\n",
    "# data[\"unigram_js_divergence\"], data[\"bigram_js_divergence\"] = zip(*data.text.apply(lambda text: char_divergences(text)))\n",
    "\n",
    "# compute gpt2 perplexity\n",
    "# gpt2_perplexity = create_gpt2_perplexity()\n",
    "# print(\"fn created\")\n",
    "# data[\"gpt2_perplexity\"] = data.text.apply(lambda text: gpt2_perplexity(text))\n",
    "\n",
    "# compute bpe tokens per char\n",
    "bpe_tokens_per_char = create_bpe_tokens_per_char()\n",
    "print(\"fn created\")\n",
    "data[\"bpe_tokens_per_char\"] = data.text.apply(lambda text: bpe_tokens_per_char(text))\n",
    "\n",
    "# print data\n",
    "# processing_now=0\n",
    "# fn_name, function, src_col = available_functions[processing_now]\n",
    "# print(f\"Processing {fn_name}\")\n",
    "\n",
    "# function = bpe_tokens_per_char\n",
    "# data[fn_name] = data[src_col].apply(lambda text: function(text))\n",
    "# data[\"gpt2_tokens_per_char\"] = data[\"text\"].apply(lambda text: function(text))\n",
    "\n",
    "# data.to_csv(f\"news.2013.de.trainlen.200.nlp.csv\", index=False)\n",
    "# data.to_csv(f\"news.2013.de.trainlen.200.char.csv\", index=False)\n",
    "# data.to_csv(f\"news.2013.de.trainlen.200.gpt2.csv\", index=False)\n",
    "data.to_csv(f\"news.2013.de.trainlen.200.bpe.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigmavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
